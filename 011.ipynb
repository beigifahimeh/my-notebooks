{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a CNN for FashionMNIST\n",
    "\n",
    "Define a CNN and train it on FashionMNIST.\n",
    "\n",
    "You should be able to beat previous fully connected networks and reach accuracy over 90%.\n",
    "If training time is too long, try using free GPUs on Google Colab (change the runtime type to GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from typing import Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import sklearn.model_selection\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "train_transforms = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_set_full = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", train=True, download=True, transform=train_transforms\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", train=False, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, target = train_set_full[231]\n",
    "plt.imshow(img.view(28, 28), cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "train_indices, val_indices = sklearn.model_selection.train_test_split(\n",
    "    range(len(train_set_full)),\n",
    "    stratify=train_set_full.targets,\n",
    "    test_size=val_size,\n",
    "    random_state=0,\n",
    ")\n",
    "train_set = torch.utils.data.Subset(train_set_full, train_indices)\n",
    "val_set = torch.utils.data.Subset(train_set_full, val_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=500, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=500, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=500, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the convolutional neural network. You can look up network components in the pytorch documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim,\n",
    "        out_dim=10,\n",
    "        img_shape=(28, 28),\n",
    "        n_layers: int = 3,\n",
    "        p: float = 0.5,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        in_dim = img_shape[0] * img_shape[1]\n",
    "        self.img_shape = img_shape\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.ReLU()))\n",
    "        for _ in range(n_layers - 2):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(p=p)\n",
    "                )\n",
    "            )\n",
    "        self.layers.append(nn.Linear(hidden_dim, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x has shape (batch_size, *img_size)\"\"\"\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels,\n",
    "        out_dim=10,\n",
    "        img_shape=(28, 28),\n",
    "        p: float = 0.5,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        in_dim = img_shape[0] * img_shape[1]\n",
    "        self.p = p\n",
    "        self.img_shape = img_shape\n",
    "        self.n_channels = n_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=5, padding=2)\n",
    "        self.norm1 = nn.BatchNorm2d(n_channels)\n",
    "        self.conv2 = nn.Conv2d(n_channels, 2*n_channels, kernel_size=3, padding=2)\n",
    "        self.norm2 = nn.BatchNorm2d(2*n_channels)\n",
    "        self.fc1 = nn.LazyLinear(out_features=4096)\n",
    "        self.fc2 = nn.Linear(4096, out_dim)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.p, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    l1_coeff:float=0\n",
    ") -> float:\n",
    "    \"\"\"Train a model for one epoch\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model to be trained\n",
    "        loader (torch.utils.data.DataLoader): Dataloader for training data\n",
    "        criterion (torch.nn.Module): loss function\n",
    "        optimizer (torch.optim.Optimizer): optimizer\n",
    "        l1_coeff (float): coefficient of L1 loss\n",
    "\n",
    "    Returns:\n",
    "        float: total loss over one epoch\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)  # I am using device as a global variable, but you could pass it as well\n",
    "        out = model(x)\n",
    "        if l1_coeff != 0:\n",
    "            params = torch.concat([params.view(-1) for params in model.parameters()])\n",
    "            l1_loss = F.l1_loss(params, torch.zeros_like(params))\n",
    "            loss = criterion(out, y) + l1_coeff * l1_loss\n",
    "        else:\n",
    "            loss = criterion(out, y)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()  # we dont want these operations to be recorded for automatic differentation, saves memory\n",
    "def validate(\n",
    "    model: torch.nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module = None,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Compute total loss and accuracy\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model to be evaluated\n",
    "        loader (torch.utils.data.DataLoader): Dataloader for evaluation data\n",
    "        criterion (torch.nn.Module, optional): loss function. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: total loss, accuracy\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        if criterion is not None:\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item()\n",
    "        total_correct += (out.argmax(dim=1) == y).sum().item()\n",
    "    return total_loss, total_correct / len(loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with a fixed architecture and add regularization one by one. Keep track of what regularization are added. How does your performance change and what is your optimal setup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 200\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# model = FeedForwardNet(hidden_dim=hidden_dim, p=0.5, n_layers=3).to(device)\n",
    "model = ConvNet(n_channels=32, p=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 50  # change this as needed\n",
    "start = perf_counter()\n",
    "for epoch in range(n_epochs):\n",
    "    train_epoch(model, train_loader, criterion, optimizer, l1_coeff=0)\n",
    "    train_loss, train_acc = validate(model, train_loader, criterion=criterion)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion=criterion)\n",
    "    print(\n",
    "        f\"{perf_counter() - start:.1f}s {epoch=}: {train_loss=:.3f}, {train_acc=:.3f}, {val_loss=:.3f}, {val_acc=:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = validate(model, test_loader, criterion=criterion)\n",
    "test_loss, test_acc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b31a3aaeeda4af9c04893663190159bf2000bd9935849b890345d37678b4dc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('idl21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
